[[dev-guide-openshift-pipeline-builds]]
= OpenShift Pipeline Builds
{product-author}
{product-version}
:data-uri:
:icons:
:experimental:
:toc: macro
:toc-title:
:prewrap!:

toc::[]

[[introduction]]

== Introduction

Whether you are creating a simple website or a complex web of microservices, it's quick
and easy to use OpenShift Pipelines to build, test, deploy, and promote your applications on OpenShift.
OpenShift Pipelines provide an OpenShift experience around Jenkins Pipelines.

In addition to standard Jenkins Pipeline Syntax, the OpenShift Jenkins image provides the OpenShift DSL
(_via the OpenShift Jenkins Client Plugin_), which aims to provide a readable, concise, comprehensive,
and fluent syntax for rich interactions with an OpenShift API server, allowing for even more fine grained
control over the build, deployment, and promotion of applications on your OpenShift cluster.

For this example, we are going to create an OpenShift Pipeline that will build, deploy, and verify a Node.js/MongoDB
application using the https://github.com/openshift/nodejs-ex/blob/master/openshift/templates/nodejs-mongodb.json[nodejs-mongodb.json] template.

[[creating-the-jenkins-master]]

== Creating the Jenkins Master

Creating the Jenkins master via the command line:

----
  // select the project that you want to use
  // or create a new project with oc new-project <project_name>
  $ oc project <project_name>
  // if you want to use persistent storage, use jenkins-persistent instead
  $ oc new-app jenkins-ephemeral
----

[NOTE]
====
If Jenkins auto-provisioning is enabled on your cluster, and you don't need to make any customizations to the
Jenkins master, you can skip the above step. For more information about Jenkins autoprovisioning see xref:../../install_config/configuring_pipeline_execution.html[Configuring Pipeline Execution].
====

[[the-pipeline-build-config]]

== The Pipeline Build Config

Now that the Jenkins master is up and running, we will create a build config that employs the Jenkins pipeline strategy
to build, deploy, and scale our Node.js/MongoDB example application.

Create a file named *nodejs-sample-pipeline.yaml* with the below content:

[source,yaml]
----
kind: "BuildConfig"
apiVersion: "v1"
metadata:
  name: "nodejs-sample-pipeline"
spec:
  strategy:
    jenkinsPipelineStrategy:
      jenkinsfile: <pipeline content from below>
    type: JenkinsPipeline
----

For more information about configuring the Pipeline Build Strategy see xref:../../builds/build_strategies.html#pipeline-strategy-options[Pipeline Strategy Options].

[[the-jenkinsfile]]

== The Jenkinsfile

Now that we have created the build config with a jenkinsPipelineStrategy, we need to tell the pipeline what to do.
We will do this by using an inline Jenkinsfile, since we aren't going to be creating our own git repository for this application.

Below is the Jenkinsfile content which is written in groovy using the OpenShift DSL.  For this example we will inline
this content into the build config using the http://www.yaml.org/spec/1.2/spec.html#id2795688[YAML Literal Style], though
including a Jenkinsfile in your source repository is the preferred Jenkins way of doing things.

The completed build config can be viewed in the OpenShift Origin repository in the examples directory: https://github.com/openshift/origin/tree/master/examples/jenkins/pipeline/nodejs-sample-pipeline.yaml[nodejs-sample-pipeline.yaml].

[source, groovy]
----
// path of the template to use
def templatePath = 'https://raw.githubusercontent.com/openshift/nodejs-ex/master/openshift/templates/nodejs-mongodb.json'
// name of the template that will be created
def templateName = 'nodejs-mongodb-example'
openshift.withCluster() {
  openshift.withProject() {
    echo "Using project: ${openshift.project()}"
    pipeline {
      agent {
        node {
          // spin up a node.js slave pod to run this build on
          label 'nodejs'
        }
      }
      options {
        // set a timeout of 20 minutes for this pipeline
        timeout(time: 20, unit: 'MINUTES')
      }
      stages {
        stage('cleanup') {
          steps {
            // delete everything with this template label
            openshift.selector("all", [ template : templateName ]).delete()
            // delete any secrets with this template label
            if (openshift.selector("secrets", templateName).exists()) {
              openshift.selector("secrets", templateName).delete()
            }
          }
        }
        stage('create') {
          steps {
            // create a new application from the templatePath
            openshift.newApp(templatePath)
          }
        }
        stage('build') {
          steps {
            def builds = openshift.selector("bc", templateName).related('builds')
            // wait up to 5 minutes for the build to complete
            timeout(5) {
              builds.untilEach(1) {
                return (it.object().status.phase == "Complete")
              }
            }
          }
        }
        stage('deploy') {
          steps {
            def rm = openshift.selector("dc", templateName).rollout()
            // wait up to 5 minutes for the deployment to complete
            timeout(5) {
              openshift.selector("dc", templateName).related('pods').untilEach(1) {
                return (it.object().status.phase == "Running")
              }
            }
          }
        }
        stage('tag') {
          steps {
            // if everything else succeeded, tag the ${templateName}:latest image as ${templateName}-staging:latest
            // a pipeline build config for the staging environment can watch for the ${templateName}-staging:latest
            // image to change and then deploy it to the staging environment
            openshift.tag("${templateName}:latest", "${templateName}-staging:latest")
          }
        }
      }
    }
  }
}
----

[NOTE]
====
The above example has been written using the *declarative pipeline* style, but the older *scripted pipeline* style is also supported.
====


[[creating-the-pipeline]]

== Creating the Pipeline

Now we can create the build config in our OpenShift cluster with the following command:

[source]
----
$ oc create -f nodejs-sample-pipeline.yaml
----

If you don't want to create your own file, you can use the sample from the Origin repository with the following command:

[source]
----
$ oc create -f https://raw.githubusercontent.com/openshift/origin/master/examples/jenkins/pipeline/nodejs-sample-pipeline.yaml
----

For more information about the OpenShift DSL syntax used here see https://github.com/openshift/jenkins-client-plugin/blob/master/README.md[OpenShift Jenkins Client Plugin].

[[starting-the-pipeline]]

== Starting the Pipeline

We can now start the pipeline with the following command:

[source]
----
$ oc start-build nodejs-sample-pipeline
----

[NOTE]
====
Alternatively, you could also start your pipeline via the OpenShift Web Console by navigating to the Builds -> Pipeline
section and clicking *Start Pipeline*, or by visiting the Jenkins Console, navigating to the Pipeline that you created,
and clicking *Build Now*.
====

Once the pipeline has started you should see the following actions performed within your project:

 * a job instance is created on the Jenkins server
 * a slave pod is launched _(if your pipeline requires one)_
 * the pipeline runs on the slave pod _(or the master if no slave is required)_
 ** any previously created resources with the *template=nodejs-mongodb-example* label will be deleted
 ** a new application (and all of it's associated resources) will be created from the *nodejs-mongodb-example* template
 ** a build will be started using the *nodejs-mongodb-example* build config
 *** the pipeline will wait until the build has completed to trigger the next stage
 ** a deployment will be started using the *nodejs-mongodb-example* deployment config
 *** the pipeline will wait until the deployment has completed to trigger the next stage
 ** if the build and deploy are successful, the *nodejs-mongodb-example:latest* image will be tagged as *nodejs-mongodb-example:stage*
 * the slave pod is deleted _(if one was required for the pipeline)_

[NOTE]
====
The best way to visualize the pipeline execution is by viewing it in the OpenShift web console.  You can view your
pipelines by logging into the web console and navigating to Builds -> Pipelines.
====

