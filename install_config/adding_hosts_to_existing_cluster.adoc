[[install-config-adding-hosts-to-cluster]]
= Adding Hosts to an Existing Cluster
{product-author}
{product-version}
:data-uri:
:icons:
:experimental:
:toc: macro
:toc-title:
:prewrap!:

toc::[]

== Overview

You can add new hosts (either nodes or masters) to your installation using the
*_scaleup.yml_* playbook for advanced installations.

[[adding-nodes-advanced]]
== Adding Hosts Using the Advanced Install

If you installed using the advanced install, you can add new hosts to your
cluster by running the *_scaleup.yml_* playbook. This playbook queries the
master, generates and distributes new certificates for the new hosts, then runs
the configuration playbooks on the new hosts only. Before running the
*_scaleup.yml_* playbook, complete all prerequisite
xref:../install_config/install/host_preparation.adoc#install-config-install-host-preparation[host preparation] steps.

You must have an existing inventory file (for example, *_/etc/ansible/hosts_*)
that is representative of your current cluster configuration in order to run the
*_scaleup.yml_* playbook.
ifdef::openshift-enterprise[]

endif::[]

[IMPORTANT]
====
The recommended maximum number of nodes is 300.
====

To add a host to an existing cluster:

. Ensure you have the latest playbooks by updating the *openshift-ansible*
packages:
+
----
# yum update openshift-ansible
----

. Edit your *_/etc/ansible/hosts_* file and add *new_<host_type>* to the
*[OSEv3:children]* section:
+
For example, to add a new node host, add *new_nodes*:
+
====
----
[OSEv3:children]
masters
nodes
new_nodes
----
====
+
To add new master hosts, add *new_masters*.

. Create a *[new_<host_type>]* section much like an existing section,
specifying host information for any new hosts you want to add. For example,
when adding a new node:
+
====
----
[nodes]
master[1:3].example.com openshift_node_labels="{'region': 'infra', 'zone': 'default'}"
node1.example.com openshift_node_labels="{'region': 'primary', 'zone': 'east'}"
node2.example.com openshift_node_labels="{'region': 'primary', 'zone': 'west'}"

[new_nodes]
node3.example.com openshift_node_labels="{'region': 'primary', 'zone': 'west'}"
----
====
+
See
xref:../install_config/install/advanced_install.adoc#advanced-host-variables[Configuring
Host Variables] for more options.
+
When adding new masters, hosts added to the *[new_masters]* section must also be
added to the *[new_nodes]* section with the `*openshift_schedulable=false*`
variable. This ensures the new master host is part of the OpenShift SDN and that
pods are not scheduled for placement on them. For example:
+
====
----
[masters]
master[1:2].example.com

[new_masters]
master3.example.com

[nodes]
node[1:3].example.com openshift_node_labels="{'region': 'infra'}"
master[1:2].example.com openshift_schedulable=false

[new_nodes]
master3.example.com openshift_schedulable=false
----
====

. Run the *_scaleup.yml_* playbook. If your inventory file is located somewhere
other than the default of *_/etc/ansible/hosts_*, specify the location with the
`-i option`.
+
For additional nodes:
+
----
# ansible-playbook [-i /path/to/file] \
    /usr/share/ansible/openshift-ansible/playbooks/byo/openshift-node/scaleup.yml
----
+
For additional masters:
+
----
# ansible-playbook [-i /path/to/file] \
    usr/share/ansible/openshift-ansible/playbooks/byo/openshift-master/scaleup.yml
----

. After the playbook completes successfully,
xref:../install_config/install/advanced_install.adoc#advanced-verifying-the-installation[verify the installation].

. Finally, move any hosts you had defined in the *[new_<host_type>]* section
into their appropriate section (but leave the *[new_<host_type>]* section
definition itself in place) so that subsequent runs using this inventory file
are aware of the nodes but do not handle them as new nodes. For example, when
adding new nodes:
+
====
----
[nodes]
master[1:3].example.com openshift_node_labels="{'region': 'infra', 'zone': 'default'}"
node1.example.com openshift_node_labels="{'region': 'primary', 'zone': 'east'}"
node2.example.com openshift_node_labels="{'region': 'primary', 'zone': 'west'}"
node3.example.com openshift_node_labels="{'region': 'primary', 'zone': 'west'}"

[new_nodes]
----

[[adding-etcd-hosts-to-existing-cluster]]
== Adding etcd Hosts to existing Cluster
You can add new etcd hosts to your cluster by running the _etcd scaleup_
playbook. This playbook queries the master, generates and distributes new
certificates for the new hosts, and then runs the configuration playbooks on the
new hosts only. Before running the etcd  *_scaleup.yml_* playbook, complete all
prerequisite
xref:../install_config/install/host_preparation.adoc#install-config-install-host-preparation[host
preparation] steps.

To add an etcd host to an existing cluster:

. Ensure you have the latest playbooks by updating the *openshift-ansible* packages:
+
[source, bash]
----
$ yum update openshift-ansible
----

. Edit your *_/etc/ansible/hosts_* file, add *new_<host_type>* to the
*[OSEv3:children]* group and add hosts under the *new_<host_type>* group:
+
For example, to add a new etcd, add *new_etcd*:
+
----
[OSEv3:children]
masters
nodes
etcd
new_etcd

[etcd]
etcd1.example.com
etcd2.example.com

[new_etcd]
etcd3.example.com
----

. Run the etcd *_scaleup.yml_* playbook. If your inventory file is located somewhere other than the default of *_/etc/ansible/hosts_*, specify the location with the `-i` option.
+
[source, bash]
----
$ ansible-playbook [-i /path/to/file] \
  /usr/share/ansible/openshift-ansible/playbooks/byo/openshift-etcd/scaleup.yml
----

. After the playbook completes successfully,
xref:../install_config/install/advanced_install.adoc#advanced-verifying-the-installation[verify the installation].
